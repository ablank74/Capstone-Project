{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35efea2",
   "metadata": {},
   "source": [
    "# # Ticket Analysis\n",
    "# This script combines traditional machine learning models and transformer-based models to classify IT tickets.\n",
    "# The process includes data loading, preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f82873",
   "metadata": {},
   "source": [
    "# ## Device Configuration\n",
    "# Check if CUDA is available and set the device accordingly. Configure XGBoost for GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb98abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "    xgb_gpu_params = {\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'predictor': 'gpu_predictor'\n",
    "    }\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    xgb_gpu_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfef09a",
   "metadata": {},
   "source": [
    "# ## Data Loading and Preprocessing\n",
    "# Load the CSV file and preprocess the data by cleaning text fields, filling missing values, and encoding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e852167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv('dataframe.csv')\n",
    "\n",
    "# Examine data structure\n",
    "print(\"\\nDataframe Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSample of raw data:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nUnique values in IT Group:\")\n",
    "print(df['fields.customfield_15404.value'].value_counts())\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text.lower()\n",
    "\n",
    "# Clean text fields\n",
    "print(\"Cleaning text fields...\")\n",
    "df['fields.summary'] = df['fields.summary'].apply(clean_text)\n",
    "df['fields.description'] = df['fields.description'].apply(clean_text)\n",
    "\n",
    "print(\"Cleaning Data...\")\n",
    "df = df[[\n",
    "    'fields.customfield_14201',\n",
    "    'fields.assignee.displayName',\n",
    "    'fields.customfield_15404.value',\n",
    "    'fields.summary',\n",
    "    'fields.description'\n",
    "]]\n",
    "\n",
    "print(\"Renaming Columns...\")\n",
    "df = df.rename(columns={\n",
    "    'fields.customfield_14201': 'Category 1',\n",
    "    'fields.assignee.displayName': 'Assignee',\n",
    "    'fields.customfield_15404.value': 'IT Group',\n",
    "    'fields.summary': 'Summary',\n",
    "    'fields.description': 'Description'\n",
    "})\n",
    "\n",
    "print(\"Filling NaN values...\")\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "df[['IT Group', 'Assignee', 'Category 1']] = imputer.fit_transform(df[['IT Group', 'Assignee', 'Category 1']])\n",
    "\n",
    "print(\"Combining Summary and Description...\")\n",
    "df['combined'] = df[['Summary', 'Description']].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "print(\"Encoding Labels...\")\n",
    "le_it_group = LabelEncoder()\n",
    "df['IT Group'] = le_it_group.fit_transform(df['IT Group'])\n",
    "\n",
    "# Ensure consecutive class labels\n",
    "unique_classes = np.sort(df['IT Group'].unique())\n",
    "class_mapping = {old: new for new, old in enumerate(unique_classes)}\n",
    "df['IT Group'] = df['IT Group'].map(class_mapping)\n",
    "\n",
    "print(\"Unique classes after remapping:\", sorted(df['IT Group'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e50c7",
   "metadata": {},
   "source": [
    "# ## Balancing the Dataset\n",
    "# Create a balanced dataset by sampling an equal number of instances from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ceef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating balanced dataset for baseline model...\")\n",
    "group_counts = df['IT Group'].value_counts()\n",
    "min_acceptable_samples = 500\n",
    "print(f\"\\nOriginal class distribution:\")\n",
    "print(group_counts)\n",
    "\n",
    "valid_groups = group_counts[group_counts >= min_acceptable_samples].index\n",
    "df_filtered = df[df['IT Group'].isin(valid_groups)]\n",
    "print(f\"\\nRemoved {len(group_counts) - len(valid_groups)} classes with fewer than {min_acceptable_samples} samples\")\n",
    "\n",
    "balanced_dfs = []\n",
    "samples_per_class = min_acceptable_samples\n",
    "for group in valid_groups:\n",
    "    group_df = df_filtered[df_filtered['IT Group'] == group]\n",
    "    if len(group_df) < samples_per_class * 1.5:\n",
    "        n_samples = int(len(group_df) * 0.8)\n",
    "    else:\n",
    "        n_samples = samples_per_class\n",
    "    sampled_df = group_df.sample(n=n_samples, random_state=42)\n",
    "    balanced_dfs.append(sampled_df)\n",
    "\n",
    "df_balanced = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "print(\"\\nFinal balanced dataset statistics:\")\n",
    "print(f\"Total samples: {len(df_balanced)}\")\n",
    "print(\"\\nSamples per class:\")\n",
    "print(df_balanced['IT Group'].value_counts())\n",
    "\n",
    "df = df_balanced\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd4d03",
   "metadata": {},
   "source": [
    "# ## Traditional Machine Learning Models\n",
    "# Train and evaluate traditional ML models like RandomForest, XGBoost, Logistic Regression, Naive Bayes, and Linear SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting Data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['combined'], df['IT Group'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Remapping labels to consecutive integers...\")\n",
    "unique_labels = sorted(set(y_train) | set(y_test))\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_train = pd.Series(y_train).map(label_map).values\n",
    "y_test = pd.Series(y_test).map(label_map).values\n",
    "\n",
    "print(\"Unique labels after remapping:\")\n",
    "print(\"Train:\", sorted(np.unique(y_train)))\n",
    "print(\"Test:\", sorted(np.unique(y_test)))\n",
    "\n",
    "pipelines = {\n",
    "    'RandomForest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000)), \n",
    "        ('clf', RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000)),\n",
    "        ('clf', XGBClassifier(\n",
    "            n_jobs=-1, \n",
    "            random_state=42,\n",
    "            objective='multi:softmax',\n",
    "            num_class=len(np.unique(y_train)),  # Make sure this matches the number of classes\n",
    "            **xgb_gpu_params\n",
    "        ))\n",
    "    ]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000)), \n",
    "        ('clf', LogisticRegression(multi_class='multinomial', max_iter=1000, n_jobs=-1))\n",
    "    ]),\n",
    "    'Naive Bayes': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000)), \n",
    "        ('clf', MultinomialNB())\n",
    "    ]),\n",
    "    'Linear SVC': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000)), \n",
    "        ('clf', LinearSVC(random_state=42, max_iter=10000))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Making predictions with {name}...\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13942a91",
   "metadata": {},
   "source": [
    "# ## Transformer-Based Models\n",
    "# Train and evaluate transformer models like BERT and RoBERTa for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_classification(df, model_name, max_len=256, batch_size=4, epochs=3, accumulation_steps=4):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df['IT Group'])\n",
    "    num_classes = len(np.unique(labels))\n",
    "    \n",
    "    texts = df['combined'].tolist()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_classes\n",
    "    ).to(device)\n",
    "    \n",
    "    if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "        model.gradient_checkpointing_enable()\n",
    "    \n",
    "    train_encodings = tokenizer(\n",
    "        X_train, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=max_len\n",
    "    )\n",
    "    test_encodings = tokenizer(\n",
    "        X_test, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=max_len\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(train_encodings['input_ids']),\n",
    "        torch.tensor(train_encodings['attention_mask']),\n",
    "        torch.tensor(y_train)\n",
    "    )\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(test_encodings['input_ids']),\n",
    "        torch.tensor(test_encodings['attention_mask']),\n",
    "        torch.tensor(y_test)\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Training\", leave=True)\n",
    "        total_loss = 0\n",
    "        batch_losses = []\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "            total_loss += loss.item() * accumulation_steps\n",
    "            batch_losses.append(loss.item() * accumulation_steps)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{sum(batch_losses[-accumulation_steps:]) / accumulation_steps:.4f}\",\n",
    "                    'avg_loss': f\"{total_loss/(batch_idx+1):.4f}\"\n",
    "                })\n",
    "                \n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed - Average Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    eval_progress = tqdm(test_loader, desc=\"Evaluating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_progress:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            eval_progress.set_postfix({\n",
    "                'batch_size': input_ids.size(0)\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n--- {model_name} Performance ---\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'tokenizer': tokenizer,\n",
    "        'label_encoder': le,\n",
    "        'predictions': predictions,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "print(\"\\nTraining Transformer Models...\")\n",
    "transformer_models = [\n",
    "    'bert-base-uncased',\n",
    "    'roberta-base'\n",
    "]\n",
    "\n",
    "transformer_results = {}\n",
    "for model_name in transformer_models:\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    try:\n",
    "        transformer_results[model_name] = transformer_classification(\n",
    "            df, \n",
    "            model_name, \n",
    "            max_len=256, \n",
    "            batch_size=4, \n",
    "            epochs=3,\n",
    "            accumulation_steps=4\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f45f4",
   "metadata": {},
   "source": [
    "# ## Save Models\n",
    "# Save the trained transformer models to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, result in transformer_results.items():\n",
    "    model_path = f'{name}_model.pth'\n",
    "    torch.save(result['model'].state_dict(), model_path)\n",
    "    print(f\"Saved {name} model to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102eda2a",
   "metadata": {},
   "source": [
    "# ## Clear Memory\n",
    "# Clear memory to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clearing Memory...\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "print(\"Done!\") \n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Combine results from both traditional ML and transformer models\n",
    "all_results = {}\n",
    "\n",
    "# Add traditional ML results\n",
    "for name, result in results.items():\n",
    "    all_results[name] = {\n",
    "        'accuracy': result['accuracy'],\n",
    "        'classification_report': result['classification_report'],\n",
    "        'model_type': 'Traditional ML'\n",
    "    }\n",
    "\n",
    "# Add transformer results\n",
    "for name in transformer_results:\n",
    "    # Extract accuracy from the last evaluation metrics\n",
    "    true_labels = transformer_results[name]['true_labels']\n",
    "    predictions = transformer_results[name]['predictions']\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions)\n",
    "    \n",
    "    all_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'model_type': 'Transformer'\n",
    "    }\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': list(all_results.keys()),\n",
    "    'Accuracy': [all_results[name]['accuracy'] for name in all_results],\n",
    "    'Model Type': [all_results[name]['model_type'] for name in all_results]\n",
    "})\n",
    "\n",
    "# Sort by accuracy\n",
    "performance_df = performance_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(performance_df[['Model', 'Model Type', 'Accuracy']])\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=performance_df,\n",
    "    x='Model',\n",
    "    y='Accuracy',\n",
    "    hue='Model Type',\n",
    "    palette=['#2ecc71', '#3498db']\n",
    ")\n",
    "\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display detailed classification reports\n",
    "print(\"\\nDetailed Classification Reports:\")\n",
    "for name in all_results:\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(all_results[name]['classification_report']) \n",
    "# %%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
